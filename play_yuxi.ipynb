{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset and save it in the same dir with this file.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel,RationalQuadratic,Exponentiation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "kf = KFold(n_splits=10)\n",
    "# import scikit learn\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getxandy(filename):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    y = df.z.to_numpy()\n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpolyxandy(filename,poly=2):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    y = df.z.to_numpy()\n",
    "    poly = PolynomialFeatures(degree=poly)\n",
    "    x = poly.fit_transform(x)\n",
    "  return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreperdataset(y_pred,y_test):\n",
    "  return np.sqrt(np.sum(np.square(y_pred - y_test))/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeresults(X_test,y_test,y_pred,f):\n",
    "    idx = np.argsort(X_test[:,0])\n",
    "    X_test = X_test[idx]\n",
    "    y_test = y_test[idx]\n",
    "    y_pred = y_pred[idx]\n",
    "    data = {}\n",
    "    data['x'] = X_test[:,0]\n",
    "    data['y'] = X_test[:,1]\n",
    "    data['z_test'] = y_test[idx]\n",
    "    data['z_pred'] = y_pred[idx]\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isdir('results/'):\n",
    "      os.mkdir('results')\n",
    "    df.to_csv('results/'+f+'.csv',float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-33432a285f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mloss_large\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreperdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pre 9 large\n",
    "\n",
    "#model = Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', DecisionTreeRegressor(max_depth=25))])\n",
    "\n",
    "finalacc_large = []\n",
    "trainfolder = 'large_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_large = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_large.append(loss)\n",
    "  print(\"{} loss {:.5f}\".format(d, loss_large))\n",
    "  #writeresults(X_test,y_test,y_pred)\n",
    "print('final average loss is {:.5f}'.format( sum(finalacc_large)/len(finalacc_large) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A loss 0.12645 \n",
      "B loss 0.17270 \n",
      "C loss 0.41336 \n",
      "D loss 0.03651 \n",
      "E loss 0.05273 \n",
      "F loss 0.22237 \n",
      "G loss 0.01887 \n",
      "H loss 0.12639 \n",
      "I loss 0.22098 \n",
      "final avg loss is 0.15448\n"
     ]
    }
   ],
   "source": [
    "# pre 9\n",
    "finalacc_small = []\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[:9]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J loss 0.74384 \n",
      "K loss 0.74708 \n",
      "L loss 0.84819 \n",
      "M loss 0.73457 \n",
      "N loss 0.72024 \n",
      "O loss 0.76775 \n",
      "P loss 0.70474 \n",
      "Q loss 0.73537 \n",
      "R loss 0.58388 \n",
      "final avg loss is 0.73174\n"
     ]
    }
   ],
   "source": [
    "# pre 9\n",
    "finalacc_small = []\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[9:]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final avg loss is 0.57828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy('small_datasets/'+'R'+'/train.csv',4)\n",
    "  clf = GridSearchCV(DecisionTreeRegressor(), {'max_depth':[10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]})\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy('small_datasets/'+'R'+'/train.csv',4)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for f is {}, maxdepth is {}'.format(loss, clf.best_estimator_.max_depth))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
