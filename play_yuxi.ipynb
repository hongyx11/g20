{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset and save it in the same dir with this file.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel,RationalQuadratic,Exponentiation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "kf = KFold(n_splits=10)\n",
    "# import scikit learn\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def getxandy(filename):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    y = df.z.to_numpy()\n",
    "  return x,y\n",
    "\n",
    "def getpolyxandy(filename,poly=2,withy=True):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    if withy:\n",
    "      y = df.z.to_numpy()\n",
    "    else:\n",
    "      y = None\n",
    "    poly = PolynomialFeatures(degree=poly)\n",
    "    x = poly.fit_transform(x)\n",
    "  return x,y\n",
    "\n",
    "def scoreperdataset(y_pred,y_test):\n",
    "  return np.sqrt(np.sum(np.square(y_pred - y_test))/len(y_pred))\n",
    "\n",
    "def writeresults(X_test,y_test,y_pred,f):\n",
    "    idx = np.argsort(X_test[:,0])\n",
    "    X_test = X_test[idx]\n",
    "    y_test = y_test[idx]\n",
    "    y_pred = y_pred[idx]\n",
    "    data = {}\n",
    "    data['x'] = X_test[:,0]\n",
    "    data['y'] = X_test[:,1]\n",
    "    data['z_test'] = y_test[idx]\n",
    "    data['z_pred'] = y_pred[idx]\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isdir('results/'):\n",
    "      os.mkdir('results')\n",
    "    df.to_csv('results/'+f+'.csv',float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A loss 0.10580 \n",
      "B loss 0.15585 \n",
      "C loss 0.37712 \n",
      "D loss 0.02422 \n",
      "E loss 0.03995 \n",
      "F loss 0.20105 \n",
      "G loss 0.01413 \n",
      "H loss 0.10852 \n",
      "I loss 0.17329 \n",
      "J loss 0.54361 \n",
      "K loss 0.54745 \n",
      "L loss 0.65704 \n",
      "M loss 0.53190 \n",
      "N loss 0.53228 \n",
      "O loss 0.56777 \n",
      "P loss 0.52624 \n",
      "Q loss 0.54025 \n",
      "R loss 0.56787 \n",
      "final avg loss is 0.34524\n"
     ]
    }
   ],
   "source": [
    "# post 9\n",
    "finalacc_small = []\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  #X,y = getxandy(trainfolder+'/'+d+'/train.csv')\n",
    "  reg = neighbors.KNeighborsRegressor(40, weights='distance')\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #break\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss for A is 0.06412215354559062, maxdepth is 6\n",
      "loss for B is 0.0860291950158973, maxdepth is 5\n",
      "loss for C is 0.27330082603780265, maxdepth is 4\n",
      "loss for D is 0.01950141390305742, maxdepth is 10\n",
      "loss for E is 0.026632842522355468, maxdepth is 7\n",
      "loss for F is 0.14575788781934573, maxdepth is 4\n",
      "loss for G is 0.010822928064590301, maxdepth is 8\n",
      "loss for H is 0.08082108592907368, maxdepth is 4\n",
      "loss for I is 0.12604355286503405, maxdepth is 4\n",
      "loss for J is 0.545831515091561, maxdepth is 33\n",
      "loss for K is 0.5421207100548354, maxdepth is 22\n",
      "loss for L is 0.6201324636392044, maxdepth is 11\n",
      "loss for M is 0.5269188279644609, maxdepth is 117\n",
      "loss for N is 0.5285231704701214, maxdepth is 86\n",
      "loss for O is 0.5693892956537249, maxdepth is 26\n",
      "loss for P is 0.5229880045531884, maxdepth is 149\n",
      "loss for Q is 0.5503204295836411, maxdepth is 51\n",
      "loss for R is 0.36882017886322005, maxdepth is 6\n",
      "final avg loss is 0.31156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(neighbors.KNeighborsRegressor(weights='distance'), {'n_neighbors':[x for x in range(1,150)]},n_jobs=30)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.n_neighbors))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_knn_small.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(neighbors.KNeighborsRegressor(weights='distance'), {'n_neighbors':[x for x in range(1,150)]},n_jobs=30)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.n_neighbors))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_knn_small.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A loss 0.13268 \n",
      "B loss 0.16972 \n",
      "C loss 0.41928 \n",
      "D loss 0.03774 \n",
      "E loss 0.05400 \n",
      "F loss 0.22874 \n",
      "G loss 0.01870 \n",
      "H loss 0.12534 \n",
      "I loss 0.21146 \n",
      "final avg loss is 0.36533\n"
     ]
    }
   ],
   "source": [
    "# pre 9\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[:9]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  #X,y = getxandy(trainfolder+'/'+d+'/train.csv')\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #break\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-33432a285f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mloss_large\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreperdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pre 9 large\n",
    "\n",
    "#model = Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', DecisionTreeRegressor(max_depth=25))])\n",
    "\n",
    "finalacc_large = []\n",
    "trainfolder = 'large_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_large = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_large.append(loss)\n",
    "  print(\"{} loss {:.5f}\".format(d, loss_large))\n",
    "  #writeresults(X_test,y_test,y_pred)\n",
    "print('final average loss is {:.5f}'.format( sum(finalacc_large)/len(finalacc_large) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "J loss 0.74672 \n",
      "K loss 0.74609 \n",
      "L loss 0.86362 \n",
      "M loss 0.72611 \n",
      "N loss 0.72007 \n",
      "O loss 0.76649 \n",
      "P loss 0.71774 \n",
      "Q loss 0.74884 \n",
      "R loss 0.60390 \n",
      "final avg loss is 0.73773\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J loss 0.74384 \n",
      "K loss 0.74708 \n",
      "L loss 0.84819 \n",
      "M loss 0.73457 \n",
      "N loss 0.72024 \n",
      "O loss 0.76775 \n",
      "P loss 0.70474 \n",
      "Q loss 0.73537 \n",
      "R loss 0.58388 \n",
      "final avg loss is 0.73174\n"
     ]
    }
   ],
   "source": [
    "# pre 9\n",
    "finalacc_small = []\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[9:]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss for A is 0.12978216995160374, maxdepth is 29\n",
      "loss for B is 0.17078259486046513, maxdepth is 30\n",
      "loss for C is 0.430947655937802, maxdepth is 24\n",
      "loss for D is 0.03718906086244351, maxdepth is 28\n",
      "loss for E is 0.05243262217126007, maxdepth is 28\n",
      "loss for F is 0.22230850240283162, maxdepth is 24\n",
      "loss for G is 0.019695002501374292, maxdepth is 29\n",
      "loss for H is 0.12333127560912857, maxdepth is 24\n",
      "loss for I is 0.20551249823222553, maxdepth is 29\n",
      "loss for J is 0.6631680250078472, maxdepth is 15\n",
      "loss for K is 0.6723312829468607, maxdepth is 16\n",
      "loss for L is 0.7761177173452065, maxdepth is 16\n",
      "loss for M is 0.562200276208805, maxdepth is 11\n",
      "loss for N is 0.5794837149891852, maxdepth is 12\n",
      "loss for O is 0.6672138611018428, maxdepth is 13\n",
      "loss for P is 0.5486853983740958, maxdepth is 10\n",
      "loss for Q is 0.6013389282433018, maxdepth is 12\n",
      "loss for R is 0.5300511255323415, maxdepth is 23\n",
      "final avg loss is 0.38848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(DecisionTreeRegressor(), {'max_depth':[10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]},n_jobs=40)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.max_depth))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_{}_pd{}.csv'.format(trainfolder,polydegree),index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           A.z       B.z       C.z       D.z       E.z       F.z       G.z  \\\n",
       "0     0.068590 -0.423999 -1.939186  0.276854  0.178814 -0.977992 -0.293425   \n",
       "1     0.578736 -0.083078 -0.997874  0.344362  0.156215 -0.774018 -0.255365   \n",
       "2    -1.385957 -1.820379 -3.232417 -0.984805 -1.474663 -3.052878 -0.462948   \n",
       "3    -0.269962  0.086945  0.610890 -0.846705 -0.613285 -0.467018 -0.366934   \n",
       "4    -0.138184 -0.170073  0.358636 -0.637182 -0.659206  0.112100 -0.409993   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -1.544600 -1.653927 -0.903935 -1.147495 -1.343468 -0.905728 -1.688055   \n",
       "9996  0.716113  0.205424 -0.095451 -0.660184 -0.719738 -1.136995 -0.185367   \n",
       "9997 -1.146646 -0.749684  0.618468 -0.976357 -1.446850 -1.532404 -0.218184   \n",
       "9998 -0.860182 -0.001287  1.070914  0.843645  1.056504  2.046295 -0.360000   \n",
       "9999  0.491971  0.286497  0.148643  0.516379  0.450561  0.425583  0.393009   \n",
       "\n",
       "           H.z       I.z       J.z       K.z       L.z       M.z       N.z  \\\n",
       "0    -0.966794  0.405307 -1.535750 -1.621131 -0.939400 -0.870400 -1.226403   \n",
       "1    -0.726360  0.439748 -0.878575 -0.399362 -1.579657 -0.826202 -0.818445   \n",
       "2    -2.074112 -2.820309 -2.681391 -2.759769 -4.749379 -3.099284 -3.331835   \n",
       "3    -0.578218 -0.011630  0.154351  0.150065  0.532862 -1.126181 -0.890864   \n",
       "4     0.381512  0.453297  0.094388 -0.336522 -0.815501  1.215569  0.576633   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -1.180908 -1.042003 -0.648542 -1.007877 -0.250274 -0.226460 -0.562846   \n",
       "9996 -1.134630 -0.652328 -0.413838 -0.428255  0.144051 -2.634563 -2.429890   \n",
       "9997 -1.043520 -1.310997 -1.468794 -1.094033 -0.669335 -3.099284 -2.511635   \n",
       "9998  1.816746  3.581599  1.601896  0.997566  1.511469  2.660580  2.186360   \n",
       "9999  0.217766  1.397163 -0.083414 -0.011237  0.437873  0.411225  0.522392   \n",
       "\n",
       "           O.z       P.z       Q.z       R.z  \n",
       "0    -0.953048 -0.916811 -1.092569  0.385946  \n",
       "1    -0.354231 -0.752633 -1.451437  0.422646  \n",
       "2    -3.841978 -2.692213 -2.756777 -2.174585  \n",
       "3    -0.653721 -0.760812 -0.737915  0.122218  \n",
       "4     0.432110  2.443393  1.695733  0.383195  \n",
       "...        ...       ...       ...       ...  \n",
       "9995 -0.834183 -0.759265 -0.854740 -0.833198  \n",
       "9996 -1.997505 -2.070956 -1.812553 -0.505799  \n",
       "9997 -1.513668 -2.060561 -1.814404 -1.203519  \n",
       "9998  2.651736  1.408421  2.149703  4.181706  \n",
       "9999  0.637368 -0.143948  0.515027  1.313026  \n",
       "\n",
       "[10000 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A.z</th>\n      <th>B.z</th>\n      <th>C.z</th>\n      <th>D.z</th>\n      <th>E.z</th>\n      <th>F.z</th>\n      <th>G.z</th>\n      <th>H.z</th>\n      <th>I.z</th>\n      <th>J.z</th>\n      <th>K.z</th>\n      <th>L.z</th>\n      <th>M.z</th>\n      <th>N.z</th>\n      <th>O.z</th>\n      <th>P.z</th>\n      <th>Q.z</th>\n      <th>R.z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.068590</td>\n      <td>-0.423999</td>\n      <td>-1.939186</td>\n      <td>0.276854</td>\n      <td>0.178814</td>\n      <td>-0.977992</td>\n      <td>-0.293425</td>\n      <td>-0.966794</td>\n      <td>0.405307</td>\n      <td>-1.535750</td>\n      <td>-1.621131</td>\n      <td>-0.939400</td>\n      <td>-0.870400</td>\n      <td>-1.226403</td>\n      <td>-0.953048</td>\n      <td>-0.916811</td>\n      <td>-1.092569</td>\n      <td>0.385946</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.578736</td>\n      <td>-0.083078</td>\n      <td>-0.997874</td>\n      <td>0.344362</td>\n      <td>0.156215</td>\n      <td>-0.774018</td>\n      <td>-0.255365</td>\n      <td>-0.726360</td>\n      <td>0.439748</td>\n      <td>-0.878575</td>\n      <td>-0.399362</td>\n      <td>-1.579657</td>\n      <td>-0.826202</td>\n      <td>-0.818445</td>\n      <td>-0.354231</td>\n      <td>-0.752633</td>\n      <td>-1.451437</td>\n      <td>0.422646</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.385957</td>\n      <td>-1.820379</td>\n      <td>-3.232417</td>\n      <td>-0.984805</td>\n      <td>-1.474663</td>\n      <td>-3.052878</td>\n      <td>-0.462948</td>\n      <td>-2.074112</td>\n      <td>-2.820309</td>\n      <td>-2.681391</td>\n      <td>-2.759769</td>\n      <td>-4.749379</td>\n      <td>-3.099284</td>\n      <td>-3.331835</td>\n      <td>-3.841978</td>\n      <td>-2.692213</td>\n      <td>-2.756777</td>\n      <td>-2.174585</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.269962</td>\n      <td>0.086945</td>\n      <td>0.610890</td>\n      <td>-0.846705</td>\n      <td>-0.613285</td>\n      <td>-0.467018</td>\n      <td>-0.366934</td>\n      <td>-0.578218</td>\n      <td>-0.011630</td>\n      <td>0.154351</td>\n      <td>0.150065</td>\n      <td>0.532862</td>\n      <td>-1.126181</td>\n      <td>-0.890864</td>\n      <td>-0.653721</td>\n      <td>-0.760812</td>\n      <td>-0.737915</td>\n      <td>0.122218</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.138184</td>\n      <td>-0.170073</td>\n      <td>0.358636</td>\n      <td>-0.637182</td>\n      <td>-0.659206</td>\n      <td>0.112100</td>\n      <td>-0.409993</td>\n      <td>0.381512</td>\n      <td>0.453297</td>\n      <td>0.094388</td>\n      <td>-0.336522</td>\n      <td>-0.815501</td>\n      <td>1.215569</td>\n      <td>0.576633</td>\n      <td>0.432110</td>\n      <td>2.443393</td>\n      <td>1.695733</td>\n      <td>0.383195</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>-1.544600</td>\n      <td>-1.653927</td>\n      <td>-0.903935</td>\n      <td>-1.147495</td>\n      <td>-1.343468</td>\n      <td>-0.905728</td>\n      <td>-1.688055</td>\n      <td>-1.180908</td>\n      <td>-1.042003</td>\n      <td>-0.648542</td>\n      <td>-1.007877</td>\n      <td>-0.250274</td>\n      <td>-0.226460</td>\n      <td>-0.562846</td>\n      <td>-0.834183</td>\n      <td>-0.759265</td>\n      <td>-0.854740</td>\n      <td>-0.833198</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.716113</td>\n      <td>0.205424</td>\n      <td>-0.095451</td>\n      <td>-0.660184</td>\n      <td>-0.719738</td>\n      <td>-1.136995</td>\n      <td>-0.185367</td>\n      <td>-1.134630</td>\n      <td>-0.652328</td>\n      <td>-0.413838</td>\n      <td>-0.428255</td>\n      <td>0.144051</td>\n      <td>-2.634563</td>\n      <td>-2.429890</td>\n      <td>-1.997505</td>\n      <td>-2.070956</td>\n      <td>-1.812553</td>\n      <td>-0.505799</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>-1.146646</td>\n      <td>-0.749684</td>\n      <td>0.618468</td>\n      <td>-0.976357</td>\n      <td>-1.446850</td>\n      <td>-1.532404</td>\n      <td>-0.218184</td>\n      <td>-1.043520</td>\n      <td>-1.310997</td>\n      <td>-1.468794</td>\n      <td>-1.094033</td>\n      <td>-0.669335</td>\n      <td>-3.099284</td>\n      <td>-2.511635</td>\n      <td>-1.513668</td>\n      <td>-2.060561</td>\n      <td>-1.814404</td>\n      <td>-1.203519</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>-0.860182</td>\n      <td>-0.001287</td>\n      <td>1.070914</td>\n      <td>0.843645</td>\n      <td>1.056504</td>\n      <td>2.046295</td>\n      <td>-0.360000</td>\n      <td>1.816746</td>\n      <td>3.581599</td>\n      <td>1.601896</td>\n      <td>0.997566</td>\n      <td>1.511469</td>\n      <td>2.660580</td>\n      <td>2.186360</td>\n      <td>2.651736</td>\n      <td>1.408421</td>\n      <td>2.149703</td>\n      <td>4.181706</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.491971</td>\n      <td>0.286497</td>\n      <td>0.148643</td>\n      <td>0.516379</td>\n      <td>0.450561</td>\n      <td>0.425583</td>\n      <td>0.393009</td>\n      <td>0.217766</td>\n      <td>1.397163</td>\n      <td>-0.083414</td>\n      <td>-0.011237</td>\n      <td>0.437873</td>\n      <td>0.411225</td>\n      <td>0.522392</td>\n      <td>0.637368</td>\n      <td>-0.143948</td>\n      <td>0.515027</td>\n      <td>1.313026</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss for A is 0.038441928844226855, maxdepth is 30\n",
      "loss for B is 0.05409639127831196, maxdepth is 30\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "WorkerInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1242, in fit\n    super().fit(\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 375, in fit\n    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\nKeyboardInterrupt\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/yhong/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 600, in __call__\n    raise WorkerInterrupt() from e\njoblib.my_exceptions.WorkerInterrupt\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mWorkerInterrupt\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-003eeb4209d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreperdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWorkerInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'large_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(DecisionTreeRegressor(), {'max_depth':[x for x in range(10,40)]},n_jobs=20)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.max_depth))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_{}_pd{}.csv'.format(trainfolder,polydegree),index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}