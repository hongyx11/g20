{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset and save it in the same dir with this file.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel,RationalQuadratic,Exponentiation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "kf = KFold(n_splits=10)\n",
    "# import scikit learn\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def getxandy(filename):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    y = df.z.to_numpy()\n",
    "  return x,y\n",
    "\n",
    "def getpolyxandy(filename,poly=2,withy=True):\n",
    "  with open(filename,'r') as f:\n",
    "    df = pd.read_csv(f,index_col=0)\n",
    "    x = np.zeros((len(df.x),2))\n",
    "    y = np.zeros((len(df.x)))\n",
    "    x[:,0] = df.x.to_numpy()\n",
    "    x[:,1] = df.y.to_numpy()\n",
    "    if withy:\n",
    "      y = df.z.to_numpy()\n",
    "    else:\n",
    "      y = None\n",
    "    poly = PolynomialFeatures(degree=poly)\n",
    "    x = poly.fit_transform(x)\n",
    "  return x,y\n",
    "\n",
    "def scoreperdataset(y_pred,y_test):\n",
    "  return np.sqrt(np.sum(np.square(y_pred - y_test))/len(y_pred))\n",
    "\n",
    "def writeresults(X_test,y_test,y_pred,f):\n",
    "    idx = np.argsort(X_test[:,0])\n",
    "    X_test = X_test[idx]\n",
    "    y_test = y_test[idx]\n",
    "    y_pred = y_pred[idx]\n",
    "    data = {}\n",
    "    data['x'] = X_test[:,0]\n",
    "    data['y'] = X_test[:,1]\n",
    "    data['z_test'] = y_test[idx]\n",
    "    data['z_pred'] = y_pred[idx]\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isdir('results/'):\n",
    "      os.mkdir('results')\n",
    "    df.to_csv('results/'+f+'.csv',float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getweights(l):\n",
    "    npl = np.array(l)\n",
    "    return np.square(1. / npl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets[9:]:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(neighbors.KNeighborsRegressor(weights=getweights), {'n_neighbors':[x for x in range(1,150)]},n_jobs=30)\n",
    "  #clf = GridSearchCV(neighbors.RadiusNeighborsRegressor(weights='uniform'), {'radius':[0.01*x for x in range(50,100)]},n_jobs=30)\n",
    "  #clf = GridSearchCV(neighbors.RadiusNeighborsRegressor(weights='distance'), {'radius':[0.01*x for x in range(1,10)]},n_jobs=30)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.n_neighbors))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "#outdf.to_csv('submission_knn_small.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "#config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 20} ) \n",
    "#sess = tf.Session(config=config) \n",
    "#keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = '/lib64:/home/yhong/hpc_sdk/Linux_x86_64/20.9/cuda/10.1/lib64:/lib:/home/yhong/yuxibuild/anaconda3/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "och 87/800\n",
      "2592/2592 - 2s - loss: 0.9327 - accuracy: 0.0000e+00 - val_loss: 0.9611 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/800\n",
      "2592/2592 - 2s - loss: 0.9301 - accuracy: 0.0000e+00 - val_loss: 0.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/800\n",
      "2592/2592 - 2s - loss: 0.9286 - accuracy: 0.0000e+00 - val_loss: 0.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/800\n",
      "2592/2592 - 2s - loss: 0.9277 - accuracy: 0.0000e+00 - val_loss: 0.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/800\n",
      "2592/2592 - 2s - loss: 0.9287 - accuracy: 0.0000e+00 - val_loss: 0.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/800\n",
      "2592/2592 - 2s - loss: 0.9253 - accuracy: 0.0000e+00 - val_loss: 0.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/800\n",
      "2592/2592 - 2s - loss: 0.9271 - accuracy: 0.0000e+00 - val_loss: 0.9012 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/800\n",
      "2592/2592 - 2s - loss: 0.9256 - accuracy: 0.0000e+00 - val_loss: 0.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/800\n",
      "2592/2592 - 2s - loss: 0.9241 - accuracy: 0.0000e+00 - val_loss: 0.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/800\n",
      "2592/2592 - 2s - loss: 0.9220 - accuracy: 0.0000e+00 - val_loss: 0.9272 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/800\n",
      "2592/2592 - 2s - loss: 0.9198 - accuracy: 0.0000e+00 - val_loss: 0.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/800\n",
      "2592/2592 - 2s - loss: 0.9154 - accuracy: 0.0000e+00 - val_loss: 0.9338 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/800\n",
      "2592/2592 - 2s - loss: 0.9164 - accuracy: 0.0000e+00 - val_loss: 0.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/800\n",
      "2592/2592 - 2s - loss: 0.9151 - accuracy: 0.0000e+00 - val_loss: 0.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/800\n",
      "2592/2592 - 2s - loss: 0.9143 - accuracy: 0.0000e+00 - val_loss: 0.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/800\n",
      "2592/2592 - 2s - loss: 0.9124 - accuracy: 0.0000e+00 - val_loss: 0.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/800\n",
      "2592/2592 - 2s - loss: 0.9094 - accuracy: 0.0000e+00 - val_loss: 0.9024 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/800\n",
      "2592/2592 - 2s - loss: 0.9095 - accuracy: 0.0000e+00 - val_loss: 0.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/800\n",
      "2592/2592 - 2s - loss: 0.9068 - accuracy: 0.0000e+00 - val_loss: 0.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/800\n",
      "2592/2592 - 2s - loss: 0.9057 - accuracy: 0.0000e+00 - val_loss: 0.8757 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/800\n",
      "2592/2592 - 2s - loss: 0.9016 - accuracy: 0.0000e+00 - val_loss: 0.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/800\n",
      "2592/2592 - 2s - loss: 0.9003 - accuracy: 0.0000e+00 - val_loss: 0.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/800\n",
      "2592/2592 - 2s - loss: 0.8991 - accuracy: 0.0000e+00 - val_loss: 0.8835 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/800\n",
      "2592/2592 - 2s - loss: 0.8968 - accuracy: 0.0000e+00 - val_loss: 0.8948 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/800\n",
      "2592/2592 - 2s - loss: 0.8957 - accuracy: 0.0000e+00 - val_loss: 0.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/800\n",
      "2592/2592 - 2s - loss: 0.8962 - accuracy: 0.0000e+00 - val_loss: 0.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/800\n",
      "2592/2592 - 2s - loss: 0.8928 - accuracy: 0.0000e+00 - val_loss: 0.8782 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/800\n",
      "2592/2592 - 2s - loss: 0.8919 - accuracy: 0.0000e+00 - val_loss: 0.8807 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/800\n",
      "2592/2592 - 2s - loss: 0.8947 - accuracy: 0.0000e+00 - val_loss: 0.8899 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/800\n",
      "2592/2592 - 2s - loss: 0.8883 - accuracy: 0.0000e+00 - val_loss: 0.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/800\n",
      "2592/2592 - 2s - loss: 0.8881 - accuracy: 0.0000e+00 - val_loss: 0.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/800\n",
      "2592/2592 - 2s - loss: 0.8866 - accuracy: 0.0000e+00 - val_loss: 0.8705 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/800\n",
      "2592/2592 - 2s - loss: 0.8866 - accuracy: 0.0000e+00 - val_loss: 0.8778 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/800\n",
      "2592/2592 - 2s - loss: 0.8850 - accuracy: 0.0000e+00 - val_loss: 0.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/800\n",
      "2592/2592 - 2s - loss: 0.8847 - accuracy: 0.0000e+00 - val_loss: 0.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/800\n",
      "2592/2592 - 2s - loss: 0.8851 - accuracy: 0.0000e+00 - val_loss: 0.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/800\n",
      "2592/2592 - 2s - loss: 0.8837 - accuracy: 0.0000e+00 - val_loss: 0.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/800\n",
      "2592/2592 - 2s - loss: 0.8804 - accuracy: 0.0000e+00 - val_loss: 0.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/800\n",
      "2592/2592 - 2s - loss: 0.8814 - accuracy: 0.0000e+00 - val_loss: 0.8480 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/800\n",
      "2592/2592 - 2s - loss: 0.8830 - accuracy: 0.0000e+00 - val_loss: 0.8659 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/800\n",
      "2592/2592 - 2s - loss: 0.8770 - accuracy: 0.0000e+00 - val_loss: 0.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/800\n",
      "2592/2592 - 2s - loss: 0.8766 - accuracy: 0.0000e+00 - val_loss: 0.8837 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/800\n",
      "2592/2592 - 2s - loss: 0.8771 - accuracy: 0.0000e+00 - val_loss: 0.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/800\n",
      "2592/2592 - 2s - loss: 0.8767 - accuracy: 0.0000e+00 - val_loss: 0.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/800\n",
      "2592/2592 - 2s - loss: 0.8775 - accuracy: 0.0000e+00 - val_loss: 0.8503 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/800\n",
      "2592/2592 - 2s - loss: 0.8720 - accuracy: 0.0000e+00 - val_loss: 0.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/800\n",
      "2592/2592 - 3s - loss: 0.8745 - accuracy: 0.0000e+00 - val_loss: 0.8548 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/800\n",
      "2592/2592 - 2s - loss: 0.8745 - accuracy: 0.0000e+00 - val_loss: 0.8769 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/800\n",
      "2592/2592 - 2s - loss: 0.8712 - accuracy: 0.0000e+00 - val_loss: 0.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/800\n",
      "2592/2592 - 2s - loss: 0.8687 - accuracy: 0.0000e+00 - val_loss: 0.8724 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/800\n",
      "2592/2592 - 2s - loss: 0.8673 - accuracy: 0.0000e+00 - val_loss: 0.8591 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/800\n",
      "2592/2592 - 2s - loss: 0.8703 - accuracy: 0.0000e+00 - val_loss: 0.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/800\n",
      "2592/2592 - 2s - loss: 0.8722 - accuracy: 0.0000e+00 - val_loss: 0.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/800\n",
      "2592/2592 - 2s - loss: 0.8690 - accuracy: 0.0000e+00 - val_loss: 0.8451 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/800\n",
      "2592/2592 - 2s - loss: 0.8661 - accuracy: 0.0000e+00 - val_loss: 0.8905 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/800\n",
      "2592/2592 - 2s - loss: 0.8655 - accuracy: 0.0000e+00 - val_loss: 0.8588 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/800\n",
      "2592/2592 - 2s - loss: 0.8653 - accuracy: 0.0000e+00 - val_loss: 0.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/800\n",
      "2592/2592 - 2s - loss: 0.8628 - accuracy: 0.0000e+00 - val_loss: 0.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/800\n",
      "2592/2592 - 2s - loss: 0.8629 - accuracy: 0.0000e+00 - val_loss: 0.8661 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/800\n",
      "2592/2592 - 2s - loss: 0.8651 - accuracy: 0.0000e+00 - val_loss: 0.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/800\n",
      "2592/2592 - 2s - loss: 0.8633 - accuracy: 0.0000e+00 - val_loss: 0.8613 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/800\n",
      "2592/2592 - 2s - loss: 0.8621 - accuracy: 0.0000e+00 - val_loss: 0.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/800\n",
      "2592/2592 - 2s - loss: 0.8618 - accuracy: 0.0000e+00 - val_loss: 0.8319 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/800\n",
      "2592/2592 - 2s - loss: 0.8614 - accuracy: 0.0000e+00 - val_loss: 0.8612 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/800\n",
      "2592/2592 - 2s - loss: 0.8654 - accuracy: 0.0000e+00 - val_loss: 0.8309 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/800\n",
      "2592/2592 - 2s - loss: 0.8565 - accuracy: 0.0000e+00 - val_loss: 0.8365 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/800\n",
      "2592/2592 - 2s - loss: 0.8603 - accuracy: 0.0000e+00 - val_loss: 0.8493 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/800\n",
      "2592/2592 - 2s - loss: 0.8599 - accuracy: 0.0000e+00 - val_loss: 0.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/800\n",
      "2592/2592 - 2s - loss: 0.8602 - accuracy: 0.0000e+00 - val_loss: 0.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/800\n",
      "2592/2592 - 2s - loss: 0.8619 - accuracy: 0.0000e+00 - val_loss: 0.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/800\n",
      "2592/2592 - 2s - loss: 0.8573 - accuracy: 0.0000e+00 - val_loss: 0.8403 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/800\n",
      "2592/2592 - 2s - loss: 0.8567 - accuracy: 0.0000e+00 - val_loss: 0.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/800\n",
      "2592/2592 - 2s - loss: 0.8560 - accuracy: 0.0000e+00 - val_loss: 0.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/800\n",
      "2592/2592 - 2s - loss: 0.8557 - accuracy: 0.0000e+00 - val_loss: 0.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/800\n",
      "2592/2592 - 2s - loss: 0.8568 - accuracy: 0.0000e+00 - val_loss: 0.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/800\n",
      "2592/2592 - 2s - loss: 0.8546 - accuracy: 0.0000e+00 - val_loss: 0.8292 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/800\n",
      "2592/2592 - 2s - loss: 0.8543 - accuracy: 0.0000e+00 - val_loss: 0.8628 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/800\n",
      "2592/2592 - 2s - loss: 0.8557 - accuracy: 0.0000e+00 - val_loss: 0.8300 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/800\n",
      "2592/2592 - 2s - loss: 0.8523 - accuracy: 0.0000e+00 - val_loss: 0.8231 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/800\n",
      "2592/2592 - 2s - loss: 0.8561 - accuracy: 0.0000e+00 - val_loss: 0.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/800\n",
      "2592/2592 - 2s - loss: 0.8533 - accuracy: 0.0000e+00 - val_loss: 0.8503 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/800\n",
      "2592/2592 - 2s - loss: 0.8526 - accuracy: 0.0000e+00 - val_loss: 0.8555 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/800\n",
      "2592/2592 - 2s - loss: 0.8533 - accuracy: 0.0000e+00 - val_loss: 0.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/800\n",
      "2592/2592 - 2s - loss: 0.8543 - accuracy: 0.0000e+00 - val_loss: 0.8429 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/800\n",
      "2592/2592 - 2s - loss: 0.8527 - accuracy: 0.0000e+00 - val_loss: 0.8329 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/800\n",
      "2592/2592 - 2s - loss: 0.8523 - accuracy: 0.0000e+00 - val_loss: 0.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/800\n",
      "2592/2592 - 2s - loss: 0.8510 - accuracy: 0.0000e+00 - val_loss: 0.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/800\n",
      "2592/2592 - 2s - loss: 0.8501 - accuracy: 0.0000e+00 - val_loss: 0.8189 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/800\n",
      "2592/2592 - 2s - loss: 0.8489 - accuracy: 0.0000e+00 - val_loss: 0.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/800\n",
      "2592/2592 - 2s - loss: 0.8491 - accuracy: 0.0000e+00 - val_loss: 0.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/800\n",
      "2592/2592 - 2s - loss: 0.8491 - accuracy: 0.0000e+00 - val_loss: 0.8225 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/800\n",
      "2592/2592 - 2s - loss: 0.8500 - accuracy: 0.0000e+00 - val_loss: 0.8254 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/800\n",
      "2592/2592 - 2s - loss: 0.8495 - accuracy: 0.0000e+00 - val_loss: 0.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/800\n",
      "2592/2592 - 2s - loss: 0.8495 - accuracy: 0.0000e+00 - val_loss: 0.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/800\n",
      "2592/2592 - 2s - loss: 0.8480 - accuracy: 0.0000e+00 - val_loss: 0.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/800\n",
      "2592/2592 - 2s - loss: 0.8489 - accuracy: 0.0000e+00 - val_loss: 0.8328 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/800\n",
      "2592/2592 - 2s - loss: 0.8479 - accuracy: 0.0000e+00 - val_loss: 0.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/800\n",
      "2592/2592 - 2s - loss: 0.8471 - accuracy: 0.0000e+00 - val_loss: 0.8308 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/800\n",
      "2592/2592 - 2s - loss: 0.8440 - accuracy: 0.0000e+00 - val_loss: 0.8460 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/800\n",
      "2592/2592 - 2s - loss: 0.8463 - accuracy: 0.0000e+00 - val_loss: 0.8304 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/800\n",
      "2592/2592 - 2s - loss: 0.8431 - accuracy: 0.0000e+00 - val_loss: 0.8278 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/800\n",
      "2592/2592 - 2s - loss: 0.8436 - accuracy: 0.0000e+00 - val_loss: 0.8184 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/800\n",
      "2592/2592 - 2s - loss: 0.8441 - accuracy: 0.0000e+00 - val_loss: 0.8194 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/800\n",
      "2592/2592 - 2s - loss: 0.8448 - accuracy: 0.0000e+00 - val_loss: 0.8240 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/800\n",
      "2592/2592 - 2s - loss: 0.8446 - accuracy: 0.0000e+00 - val_loss: 0.8183 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/800\n",
      "2592/2592 - 2s - loss: 0.8403 - accuracy: 0.0000e+00 - val_loss: 0.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/800\n",
      "2592/2592 - 2s - loss: 0.8443 - accuracy: 0.0000e+00 - val_loss: 0.8195 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/800\n",
      "2592/2592 - 2s - loss: 0.8400 - accuracy: 0.0000e+00 - val_loss: 0.8184 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/800\n",
      "2592/2592 - 2s - loss: 0.8426 - accuracy: 0.0000e+00 - val_loss: 0.8173 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/800\n",
      "2592/2592 - 2s - loss: 0.8391 - accuracy: 0.0000e+00 - val_loss: 0.8154 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/800\n",
      "2592/2592 - 2s - loss: 0.8425 - accuracy: 0.0000e+00 - val_loss: 0.8502 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/800\n",
      "2592/2592 - 2s - loss: 0.8417 - accuracy: 0.0000e+00 - val_loss: 0.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/800\n",
      "2592/2592 - 2s - loss: 0.8399 - accuracy: 0.0000e+00 - val_loss: 0.8946 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/800\n",
      "2592/2592 - 2s - loss: 0.8436 - accuracy: 0.0000e+00 - val_loss: 0.8254 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/800\n",
      "2592/2592 - 2s - loss: 0.8395 - accuracy: 0.0000e+00 - val_loss: 0.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/800\n",
      "2592/2592 - 2s - loss: 0.8396 - accuracy: 0.0000e+00 - val_loss: 0.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/800\n",
      "2592/2592 - 2s - loss: 0.8373 - accuracy: 0.0000e+00 - val_loss: 0.8353 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/800\n",
      "2592/2592 - 2s - loss: 0.8398 - accuracy: 0.0000e+00 - val_loss: 0.8333 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/800\n",
      "2592/2592 - 2s - loss: 0.8396 - accuracy: 0.0000e+00 - val_loss: 0.8591 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/800\n",
      "2592/2592 - 2s - loss: 0.8374 - accuracy: 0.0000e+00 - val_loss: 0.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/800\n",
      "2592/2592 - 2s - loss: 0.8373 - accuracy: 0.0000e+00 - val_loss: 0.8429 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/800\n",
      "2592/2592 - 2s - loss: 0.8375 - accuracy: 0.0000e+00 - val_loss: 0.8222 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/800\n",
      "2592/2592 - 2s - loss: 0.8388 - accuracy: 0.0000e+00 - val_loss: 0.8373 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/800\n",
      "2592/2592 - 2s - loss: 0.8348 - accuracy: 0.0000e+00 - val_loss: 0.8127 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/800\n",
      "2592/2592 - 2s - loss: 0.8366 - accuracy: 0.0000e+00 - val_loss: 0.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/800\n",
      "2592/2592 - 2s - loss: 0.8357 - accuracy: 0.0000e+00 - val_loss: 0.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/800\n",
      "2592/2592 - 2s - loss: 0.8369 - accuracy: 0.0000e+00 - val_loss: 0.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/800\n",
      "2592/2592 - 2s - loss: 0.8348 - accuracy: 0.0000e+00 - val_loss: 0.8122 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/800\n",
      "2592/2592 - 2s - loss: 0.8367 - accuracy: 0.0000e+00 - val_loss: 0.8160 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/800\n",
      "2592/2592 - 2s - loss: 0.8336 - accuracy: 0.0000e+00 - val_loss: 0.8372 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/800\n",
      "2592/2592 - 2s - loss: 0.8351 - accuracy: 0.0000e+00 - val_loss: 0.8119 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/800\n",
      "2592/2592 - 2s - loss: 0.8327 - accuracy: 0.0000e+00 - val_loss: 0.8094 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/800\n",
      "2592/2592 - 2s - loss: 0.8341 - accuracy: 0.0000e+00 - val_loss: 0.8274 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/800\n",
      "2592/2592 - 2s - loss: 0.8337 - accuracy: 0.0000e+00 - val_loss: 0.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/800\n",
      "2592/2592 - 2s - loss: 0.8331 - accuracy: 0.0000e+00 - val_loss: 0.8409 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/800\n",
      "2592/2592 - 2s - loss: 0.8330 - accuracy: 0.0000e+00 - val_loss: 0.8224 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/800\n",
      "2592/2592 - 2s - loss: 0.8329 - accuracy: 0.0000e+00 - val_loss: 0.8160 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/800\n",
      "2592/2592 - 2s - loss: 0.8332 - accuracy: 0.0000e+00 - val_loss: 0.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/800\n",
      "2592/2592 - 2s - loss: 0.8324 - accuracy: 0.0000e+00 - val_loss: 0.8183 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/800\n",
      "2592/2592 - 2s - loss: 0.8337 - accuracy: 0.0000e+00 - val_loss: 0.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/800\n",
      "2592/2592 - 2s - loss: 0.8315 - accuracy: 0.0000e+00 - val_loss: 0.8225 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/800\n",
      "2592/2592 - 2s - loss: 0.8296 - accuracy: 0.0000e+00 - val_loss: 0.8244 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/800\n",
      "2592/2592 - 2s - loss: 0.8325 - accuracy: 0.0000e+00 - val_loss: 0.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/800\n",
      "2592/2592 - 2s - loss: 0.8324 - accuracy: 0.0000e+00 - val_loss: 0.8153 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/800\n",
      "2592/2592 - 2s - loss: 0.8287 - accuracy: 0.0000e+00 - val_loss: 0.8348 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/800\n",
      "2592/2592 - 2s - loss: 0.8281 - accuracy: 0.0000e+00 - val_loss: 0.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/800\n",
      "2592/2592 - 2s - loss: 0.8322 - accuracy: 0.0000e+00 - val_loss: 0.8189 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/800\n",
      "2592/2592 - 2s - loss: 0.8289 - accuracy: 0.0000e+00 - val_loss: 0.8096 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/800\n",
      "2592/2592 - 2s - loss: 0.8304 - accuracy: 0.0000e+00 - val_loss: 0.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/800\n",
      "2592/2592 - 2s - loss: 0.8274 - accuracy: 0.0000e+00 - val_loss: 0.8399 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/800\n",
      "2592/2592 - 2s - loss: 0.8305 - accuracy: 0.0000e+00 - val_loss: 0.8028 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/800\n",
      "2592/2592 - 2s - loss: 0.8290 - accuracy: 0.0000e+00 - val_loss: 0.8019 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/800\n",
      "2592/2592 - 2s - loss: 0.8286 - accuracy: 0.0000e+00 - val_loss: 0.8136 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/800\n",
      "2592/2592 - 2s - loss: 0.8284 - accuracy: 0.0000e+00 - val_loss: 0.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/800\n",
      "2592/2592 - 2s - loss: 0.8264 - accuracy: 0.0000e+00 - val_loss: 0.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/800\n",
      "2592/2592 - 2s - loss: 0.8282 - accuracy: 0.0000e+00 - val_loss: 0.8179 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/800\n",
      "2592/2592 - 2s - loss: 0.8293 - accuracy: 0.0000e+00 - val_loss: 0.8089 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/800\n",
      "2592/2592 - 2s - loss: 0.8313 - accuracy: 0.0000e+00 - val_loss: 0.8274 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/800\n",
      "2592/2592 - 2s - loss: 0.8270 - accuracy: 0.0000e+00 - val_loss: 0.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/800\n",
      "2592/2592 - 2s - loss: 0.8276 - accuracy: 0.0000e+00 - val_loss: 0.8186 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/800\n",
      "2592/2592 - 2s - loss: 0.8271 - accuracy: 0.0000e+00 - val_loss: 0.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/800\n",
      "2592/2592 - 2s - loss: 0.8253 - accuracy: 0.0000e+00 - val_loss: 0.8129 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/800\n",
      "2592/2592 - 2s - loss: 0.8275 - accuracy: 0.0000e+00 - val_loss: 0.8440 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/800\n",
      "2592/2592 - 2s - loss: 0.8231 - accuracy: 0.0000e+00 - val_loss: 0.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/800\n",
      "2592/2592 - 2s - loss: 0.8263 - accuracy: 0.0000e+00 - val_loss: 0.8314 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/800\n",
      "2592/2592 - 2s - loss: 0.8259 - accuracy: 0.0000e+00 - val_loss: 0.8204 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/800\n",
      "2592/2592 - 2s - loss: 0.8242 - accuracy: 0.0000e+00 - val_loss: 0.8261 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/800\n",
      "2592/2592 - 2s - loss: 0.8230 - accuracy: 0.0000e+00 - val_loss: 0.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/800\n",
      "2592/2592 - 2s - loss: 0.8227 - accuracy: 0.0000e+00 - val_loss: 0.8134 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/800\n",
      "2592/2592 - 2s - loss: 0.8245 - accuracy: 0.0000e+00 - val_loss: 0.8136 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/800\n",
      "2592/2592 - 2s - loss: 0.8272 - accuracy: 0.0000e+00 - val_loss: 0.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/800\n",
      "2592/2592 - 2s - loss: 0.8242 - accuracy: 0.0000e+00 - val_loss: 0.8176 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/800\n",
      "2592/2592 - 2s - loss: 0.8244 - accuracy: 0.0000e+00 - val_loss: 0.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/800\n",
      "2592/2592 - 2s - loss: 0.8264 - accuracy: 0.0000e+00 - val_loss: 0.7975 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/800\n",
      "2592/2592 - 2s - loss: 0.8224 - accuracy: 0.0000e+00 - val_loss: 0.8217 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/800\n",
      "2592/2592 - 2s - loss: 0.8224 - accuracy: 0.0000e+00 - val_loss: 0.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/800\n",
      "2592/2592 - 2s - loss: 0.8231 - accuracy: 0.0000e+00 - val_loss: 0.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/800\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-331b0c68b2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
      "\u001b[0;32m~/yuxibuild/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3003\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m         tld.op_callbacks, dataset, iterator)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "trainfolder = 'small_datasets/'\n",
    "polydegree=4\n",
    "X,y = getpolyxandy(trainfolder+'J'+'/train.csv',polydegree)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 20} ) \n",
    "# sess = tf.Session(config=config) \n",
    "# keras.backend.set_session(sess)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(40, activation=\"relu\", input_dim=X.shape[1], kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(20, activation=\"relu\", input_dim=40, kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(10, activation=\"relu\", input_dim=20, kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=800, batch_size=50,validation_split=0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(neighbors.KNeighborsRegressor(weights='distance'), {'n_neighbors':[x for x in range(1,150)]},n_jobs=30)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.n_neighbors))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_knn_small.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(neighbors.KNeighborsRegressor(weights='distance'), {'n_neighbors':[x for x in range(1,150)]},n_jobs=30)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.n_neighbors))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_knn_small.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre 9\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[:9]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  #X,y = getxandy(trainfolder+'/'+d+'/train.csv')\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #break\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre 9 large\n",
    "\n",
    "#model = Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', DecisionTreeRegressor(max_depth=25))])\n",
    "\n",
    "finalacc_large = []\n",
    "trainfolder = 'large_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_large = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_large.append(loss)\n",
    "  print(\"{} loss {:.5f}\".format(d, loss_large))\n",
    "  #writeresults(X_test,y_test,y_pred)\n",
    "print('final average loss is {:.5f}'.format( sum(finalacc_large)/len(finalacc_large) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre 9\n",
    "finalacc_small = []\n",
    "trainfolder = 'small_datasets'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "for d in datasets[9:]:\n",
    "  X,y = getpolyxandy(trainfolder+'/'+ d +'/train.csv',4)\n",
    "  reg = DecisionTreeRegressor(max_depth=25)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n",
    "  reg.fit(X_train,y_train)\n",
    "  y_pred = reg.predict(X_test)\n",
    "  loss_small = scoreperdataset(y_pred, y_test)\n",
    "  finalacc_small.append(loss_small)\n",
    "  print(\"{} loss {:.5f} \".format(d, loss_small))\n",
    "  #writeresults(X_test,y_test,y_pred,f[9:])\n",
    "print('final avg loss is {:.5f}'.format(sum(finalacc_small)/len(finalacc_small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'small_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(DecisionTreeRegressor(), {'max_depth':[10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]},n_jobs=40)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.max_depth))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_{}_pd{}.csv'.format(trainfolder,polydegree),index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "final_acc = []\n",
    "pred_array = {}\n",
    "trainfolder = 'large_datasets/'\n",
    "datasets = [chr(ord('A') + x) for x in range(18)]\n",
    "polydegree=4\n",
    "for d in datasets:\n",
    "  X,y = getpolyxandy(trainfolder+d+'/train.csv',polydegree)\n",
    "  clf = GridSearchCV(DecisionTreeRegressor(), {'max_depth':[x for x in range(10,40)]},n_jobs=20)\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=1)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.best_estimator_.predict(X_test)\n",
    "  loss = scoreperdataset(y_pred,y_test)\n",
    "  final_acc.append(loss)\n",
    "  X_real,y_real = getpolyxandy(trainfolder+d+'/test.csv',polydegree,withy=False)\n",
    "  y_real_pred = clf.best_estimator_.predict(X_real)\n",
    "  pred_array[d+'.z'] = y_real_pred\n",
    "  print('loss for {} is {}, maxdepth is {}'.format(d,loss, clf.best_estimator_.max_depth))\n",
    "print('final avg loss is {:.5f}'.format( sum(final_acc)/len(final_acc)))\n",
    "outdf = pd.DataFrame(pred_array)\n",
    "outdf.to_csv('submission_{}_pd{}.csv'.format(trainfolder,polydegree),index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}